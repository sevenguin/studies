##Google TFX

paper:

http://www.kdd.org/kdd2017/papers/view/tfx-a-tensorflow-based-production-scale-machine-learning-platform



###从训练数据中生成模型

分析模块

数据验证和模型验证模块

几个可能构建系统时的问题：

1. 创建一个机器学习平台，支持许多不同的学习任务
   1. 会有不同的数据表示，存储结构，机器学习任务
   2. 处理最通用的一些学习任务，也能够灵活到扩展一些临时的用例
2. 持续训练和提供服务
   1. 既可以对固定数据集训练模型，也可以持续训练每天来训练数据
3. 可视化界面，简单的部署和监控
4. 产品级别的可扩展性和健壮性



### 数据分析/转换/验证

#### 数据分析

处理数据集

生成一些数据描述

 	1. 每一个特征表征统计值， 例如：数值分布/特征的有值比率
 	2. 每个特征的值的统计量，例如：对于连续变量*位数*，*等高直方图*，均值和标准差等。对于离散性变量，包括离散值的频数的前K个值（top-K values by frequency）.
 	3. 支持可配的切片信息的统计，例如：正负比例数的统计
 	4. 特征之间的统计量（特征之间的相关系数）

#### 数据转换

主要需要考虑的问题是保持对训练数据的转换和对线上数据的转换的一致性。

id space?

#### 数据验证

数据分析结束，接下来要作的就是数据验证，数据是否正常，或者有没有异常数据需要标注出来（可以使用异常检验的算法来检验异常数据，并且标注出来）

这一层依赖一个关于feature的schema，提供支持赋予期望数据版本并能简单的对数据进行描述。下面是一个示例：

* feature name
* feature datatype
* 每一个feature的数据表征，诸如数据最少数量/比例或者是否必须等
* 每一个特征的一些数值统计两，例如最大最小值
* 特征的期望定义域，例如字符串标签或者数值范围
* 其他诸如是否已经不用（deprecated）

```json
feature{
    name: 'category'
    presence: REQUIRED
    type: String
    domain: {
    	value: 'GAMES'
  		value: 'BUSINESS'
	}
}
```



使用schema和training example来校验数据（但是如果测试数据是异常呢？）

在校验出问题时，需要能够支持将这类数据deprecated（打上标记）或者直接修正schema。并且能够从统计数据中生成一个版本的schema。

在决定需要哪些schema的properties时，可以依据下面一些设计准则：

* 用户能够对异常数据有一个概览以及在所有数据的一个覆盖情况
* 每一个异常能够有一个简单的描述来帮助用户来修复数据或者schema，一个例子就是feature value超出了定义的range范围
* 每一个异常最好能够产生一个数据schema
* 需要认真对待数据异常情况，就像代码bug一样，写入文档，利于跟踪和优化。

### 模型训练

#### Warm-Starting

warm-start新模型，主要就是一些迁移学习。

TFX的paper里面主要介绍的都是nn参数的迁移，例如先用base data训练一个base model，然后将base model的参数作为实际模型的一个初始值。

#### 使用更高级的模型API

使用更高级的API而不是底层的，更高级的API将实现细节隐藏。

例如FeatureColumns和Estimator

一个调优器集成到机器学习系统里面，训练时可以自动优化超参数（基于我们的目标函数和数据），则是很有用的。一般都是线训练一个简单的模型，来作为基线，然后根据这个基线，分析数据，训练更复杂的数据。

### 模型评估和校验

确保模型是在线上可用；以及模型达到预期效果。

使用AUC等human-facing指标来决定模型是否被采用（A/Btest，确保达到预期），使用machine-facing来validate模型，从而判断模型的好坏（确保可用）。

#### slicing

可以对数据进行切片测试，从而知道模型在某个切片上的效果，从而可以专注于这个切片优化模型，避免模型只在总体上表现良好而在某个切片上表现较差。例如Country='us'

### 模型线上服务







retrieve

rank



层数增加式的迭代增加