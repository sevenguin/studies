## 统计学习方法

监督学习：给定的有限的训练数据集合中，假设数据是独立同分布产生的，并且假设要学习的模型属于某个函数的集合，称为假设空间，应用某个评价标准，从假设空间中选取一个最优的模型，使他对已知训练数据以及未知测试数据在给定的评价标准下有最优的预测。所以模型主要包括：假设空间，模型选择的准则以及模型学习的算法

统计学习三要素：方法= 模型+策略+算法

* 模型：模型就是要学习的决策函数或概率分布，模型的假设空间包括所有可能取值的决策函数或概率分布

* 策略：在确定了模型的假设空间，则需要考虑按照什么样的准则和方法选择最优模型。

  * 损失函数和风险函数：用损失函数来度量预测错误的程度，损失函数是f(X)和Y的非负实值函数，记作L(Y,f(X))，常用的损失函数：

    * 0-1损失函数：$L(Y,f(X))=1\ if\ Y\ne f(X) else 0$
    * 平方损失函数：$L(Y, f(X)) = (Y - f(X))^2$
    * 绝对损失函数：$L(Y, f(X)) = |Y - f(X)|$
    * 对数损失函数：$L(Y, f(X)) = -\log P(Y|X)$

    损失函数的期望是：
    $$
    R_{exp}(f)=E_p[L(Y, f(X))] = \int_{x\times y}L(y, f(x))P(x,y)dxdy
    $$
    称之为风险函数或期望损失。

    一般通过对训练数据集的经验风险来估计损失函数期望（因为X和Y的联合分布未知），经验风险如下：
    $$
    R_{emp} = {1\over N}\sum_{i=1}^NL(y_i, f(x_i))
    $$

  * 经验风险最小化与结构风险最小化：如果数据量不足，经验封校最小化可能会导致过拟合，结构化风险就是为了防止过拟合而提出的策略，结构风险最小化等价于正则化。结构化风险在经验风险上增加模型复杂度的正则化或罚项。结构风险的定义是：
    $$
    R_srm = {1\over N}\sum_{i=1}^NL(y_i, f(x_i)) + \lambda J(f)
    $$

*  算法：算法是指学习模型具体计算方法，基本就是最优化问题的算法。

### 模型评估与模型选择

训练误差：训练数据中产生的误差；测试误差：测试数据时产生的误差。

两者都是通过计算经验风险来评估，只是两者计算的样本容量不同。

### 正则化与交叉验证

#### 正则化

模型选择的典型方法就是正则化，正则化是结构风险最小化策略的实现。正则化一般形式如下：
$$
min_{f\in F}{1\over N}\sum_{i =1}^N L(y_i, f(x_i)) + \lambda J(f)
$$
其中$J(f)$可以是$L_2$范数，或$L_1$范式。

#### 交叉验证

随机将数据切分成三部分：训练集、验证集合测试集，训练集用来训练模型，验证集用来进行模型选择，测试集用来对最终学习方法进行评估。

* 简单交叉验证：只分为训练集和测试集，选出测试集上测试误差较小的模型
* S折交叉验证：将数据随机分为S个互相交大小相同的数据集，然后利用S-1个数据训练数据，利用余下的子集测试模型，将这种方式进行S次，选择模型中平均误差较小的。
* 留一交叉验证：S折交叉验证的特殊情况，S=N

### 泛化能力

泛化能力是指学习模型在未知数据上预测的能力，一般使用测试误差来进行评估。泛化误差（generalization error）就是把经验误差中的f替换成$\hat f$——学习到的模型。

泛化误差上界：

对二类问题，当假设空间是有限个函数的集合：$F={f_1, f_2, ..., f_d}$，对于任意$f\in F$， 至少以概率$1 - \delta$，以下不等式成立：
$$
R(f) \le \hat R(f) + \epsilon(d, N, \delta)，其中\epsilon(d, N, \delta)=\sqrt{{1\over 2N}(\log d + \log{1\over \delta})}
$$

### 生成模型和判别模型

生成模型（generative model）通过学习联合概率分布$P(X,Y)$，然后求出条件概率分布$P(Y|X)$，即生成模型：$P(Y|X)={P(X,Y)\over P(X)}$，之所以叫生成模型应为模型表示了给定输入X和给定输出Y的生成关系，典型的生成模型有：朴素贝叶斯和隐形马尔科夫模型。

生成模型的的特点：

* 学习收敛速度快
* 计算出X,Y联合分布
* 当存在隐变量时，生成方法仍然可用

判别模型（discriminative model）直接学习决策函数$f(X)$或$P(Y|X)$为预测模型。

判别模型的特点：

* 直接得到决策函数，往往准确率较高
* 由于直接学习，所以可以对数据进行各种程度上的抽象

### 分类、标注、回归问题

#### 分类问题

这里主要说明一下评价分类性能的指标：

* 分类准确率（accuracy）：正确分类的样本数与总样本数之比
* 精确率（precision）和召回率（recall）：对于二类问题使用，将类别分为正类和负类两个，精确率为：$P={TP\over TP+FP}$，召回率：$R = {TP\over TP+FN}$，TP是正类分为正类；FP是负类分为正类；FN是正类分为负类；TN是负类分为负类。
* $F_1$值：精确率和召回率的调和均值，即：${2\over F_1}={1\over P} + {1\over R}，F_1={2TP\over 2TP+FP+FN}$。

#### 标注问题

标注问题和分类问题相似，但是更复杂，标注问题的输入是一个观测序列，输出是一个标记序列或状态序列。标注问题的目标在于学习一个模型，使它能够对观测序列给出标记序列作为预测。

例如对语句进行分词、提取信息等。标注常用的统计学习方法有：隐形马尔科夫模型，条件随机场。

#### 回归问题

回归模型是表示输入变量到输出变量之间的映射的函数，回归问题等价于函数拟合，选择一条函数曲线使其很好的拟合已知数据且很好的拟合未知数据。




## 模型评估

### 线性回归模型

#### $R^2$score, the coefficient of determination

 [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination)：决策系数，是一个数字，可以从自变量预测的因变量中的方差的比例的数字。即回归平方和（SSR）在总变差（SST）中占的比重，可以作为综合度量回归模型对样本观测值拟合优度的度量指标。说明解释变量对因变量的解释程度，可以用来判断线性回归的拟合效果，取值[0,1]。一般表示为$R^2, r^2$。
$$
R^2(y,\hat y) = 1 - {\sum_{i=0}^{n-1}(y_i - \hat y_i)^2\over \sum_{i=0}^{n-1}(y_i - \overline y)^2}，n是样本数，后面那一项表示总残差平方和占离差平方和的比例，越小说明拟合越好
$$
和相关系数一样，度量两个变量之间的关系，但是两者之间还是有些差别。

相关系数（r）用来度量__定距变量__间的线性相关性，反映了两个变量线性关系的方向和密切程度，没有单位。取值范围为[-1,1]，其却对值越大，则说明两个变量线性关系越好，反之线性关系越差或不存在，正号表示正相关，符号表示负相关。
$$
r={\sum_{i=1}^n(x_i -\overline x) (y_i - \overline y)\over \sqrt{\sum_{i=1}^n(x_i - \overline x)^2\sum_{i=1}(y_i - \overline y)^2}}
$$


定距变量：统计学依据数据的计量尺度将数据划分为四大类，即定距型数据（Interval Scale）、定序型数据（Ordinal Scale）、定类型数据（Nominal Scale）和定比型数据 (Ratio Scale)。定距型数据是数字型变量，可以求加减平均值等，但不存在基准0值，即当变量值为0时不是表示没有，如温度变量，当温度为0时，并不是表示没有温度，这样温度就为定距变量，而不是定比变量；定序型数据具有内在固有大小或高低顺序，但它又不同于定距型数据，一般可以数值或字符表示。如职称变量可以有低级、中级和高级三个取值，可以分别用1、2、3等表示，年龄段变量可以有老、中、青三个取值，分别用A、B、C表示等。摘自[百度百科](http://baike.baidu.com/link?url=mGAnoReZOlx5oH8_wGkQu25FAft9LSO4vQLid74gEFclL1cfSA3KLacH-wrrzJjLDdmvzU8hdTz5SkfBwRpt_gVhdFTauYjivZkkfVmE2WF90B8bnYqsgdkcvN8iZqQ6)。

可以根据相关程度判定是否进行回归分析，相关系数度量变量之间的线性关系的强弱程度或共变趋势。

scikit-learn库中`sklearn.metrics.r2_score`计算$R^2$。



