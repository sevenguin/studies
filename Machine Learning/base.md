
统计学习方法：

1. 监督学习：给定的有限的训练数据集合中，假设数据是独立同分布产生的，并且假设要学习的模型属于某个函数的集合，称为假设空间，应用某个评价标准，从假设空间中选取一个最优的模型，使他对已知训练数据以及未知测试数据在给定的评价标准下有最优的预测。所以模型主要包括：假设空间，模型选择的准则以及模型学习的算法

策略：有了模型空间，统计学习需要考虑按照什么样的准则学习或选择最优的模型（从模型空间中）。使用损失函数来判断一次预测的好坏，使用风险函数度量平均意义下模型预测的好坏。     
平常使用的损失函数：    




## 模型评估

### 线性回归模型

#### $R^2$score, the coefficient of determination

 [coefficient of determination](https://en.wikipedia.org/wiki/Coefficient_of_determination)：决策系数，是一个数字，可以从自变量预测的因变量中的方差的比例的数字。即回归平方和（SSR）在总变差（SST）中占的比重，可以作为综合度量回归模型对样本观测值拟合优度的度量指标。说明解释变量对因变量的解释程度，可以用来判断线性回归的拟合效果，取值[0,1]。一般表示为$R^2, r^2$。
$$
R^2(y,\hat y) = 1 - {\sum_{i=0}^{n-1}(y_i - \hat y_i)^2\over \sum_{i=0}^{n-1}(y_i - \overline y)^2}，n是样本数，后面那一项表示总残差平方和占离差平方和的比例，越小说明拟合越好
$$
和相关系数一样，度量两个变量之间的关系，但是两者之间还是有些差别。

相关系数（r）用来度量__定距变量__间的线性相关性，反映了两个变量线性关系的方向和密切程度，没有单位。取值范围为[-1,1]，其却对值越大，则说明两个变量线性关系越好，反之线性关系越差或不存在，正号表示正相关，符号表示负相关。
$$
r={\sum_{i=1}^n(x_i -\overline x) (y_i - \overline y)\over \sqrt{\sum_{i=1}^n(x_i - \overline x)^2\sum_{i=1}(y_i - \overline y)^2}}
$$


定距变量：统计学依据数据的计量尺度将数据划分为四大类，即定距型数据（Interval Scale）、定序型数据（Ordinal Scale）、定类型数据（Nominal Scale）和定比型数据 (Ratio Scale)。定距型数据是数字型变量，可以求加减平均值等，但不存在基准0值，即当变量值为0时不是表示没有，如温度变量，当温度为0时，并不是表示没有温度，这样温度就为定距变量，而不是定比变量；定序型数据具有内在固有大小或高低顺序，但它又不同于定距型数据，一般可以数值或字符表示。如职称变量可以有低级、中级和高级三个取值，可以分别用1、2、3等表示，年龄段变量可以有老、中、青三个取值，分别用A、B、C表示等。摘自[百度百科](http://baike.baidu.com/link?url=mGAnoReZOlx5oH8_wGkQu25FAft9LSO4vQLid74gEFclL1cfSA3KLacH-wrrzJjLDdmvzU8hdTz5SkfBwRpt_gVhdFTauYjivZkkfVmE2WF90B8bnYqsgdkcvN8iZqQ6)。

可以根据相关程度判定是否进行回归分析，相关系数度量变量之间的线性关系的强弱程度或共变趋势。

scikit-learn库中`sklearn.metrics.r2_score`计算$R^2$。



