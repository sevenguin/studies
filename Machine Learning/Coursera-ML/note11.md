## Machine Learning System Design

### Prioritizing what to work on：Spam classification example

如何来降低垃圾邮件分类的错误：

1. 收集更多的数据："honeypot"project-故意将一个错误的邮件地址泄露给垃圾邮件发送者，然后就可以收集很多数据
2. 开发更复杂的特征，基于邮件的路由信息（例如邮件头）
3. 开发更复杂的特征，从邮件内容中，例如：是否将discount和discounts当做相同的词
4. 开发更复杂的特征，来检测垃圾邮件故意的拼写错误，例如：discount拼写为disc0unt

这种类型的问题，群策群力会更好，能够收到更好的效果，得到更多的有用的方法。

### Error Analysis

误差分析：会帮助我们更好的决策如何来选择一个更好的算法来使用

在打算构建一个机器学习系统之前，几个建议：

- 从一个简单的算法开始：可以快速的实现、快速的在交叉数据集上验证（NG：开始时只花1天时间来做，即使效果不好）--投石问路
- 画出学习曲线（plot learning curves）：找出算法是高偏差还是高误差，从而决定使用更多数据、特征或修改算法。这样就有证据来将我们的时间引向某些方向，而不是直觉
- 误差分析：人工去分析交叉验证集中那些被算法错误分类的数据，发现什么类型的数据可能会被错误处理，从而得到更多的优化信息。
- 保证自己能有数值计算的方式来评估自己的机器学习算法:这样就会很快的评估新发现的方法是否有用，是否采用。 

"Porter stemmer"词干提取（例如：discount/discounts/discounted)

### Error Metrics for Skewed Classes

Skewed Classes：偏斜类，即各个类的数量分布不均衡，例如：预测是否为有癌症，有癌症的概率为0.05%，也就是没有和右的比率很小，而算法预测的误差率1%，说明比全部猜成无癌症效果更差。

使用精确度来度量偏斜类问题时就会出现问题，例如上面说的，得癌症的概率0.05%，假设算法的误差率为1%，那新算法的概率是0.05%，那很明显新算法有提升，但是新算法可能是：

```matlab
function y = predictCancer(x)
    y = 0;     %ignore x!
return
```

完全没有预测，所以偏斜类问题可能由于其自身类别分配的原因导致误差率很小，从而误导了我们优化算法的方向，因此对这类问题，可以使用其他的一些评估方法。

__Precision/Recall__：查准率或召回率，查准率即预测为真且实际为真的数量和预测为真的数量的比率；召回率是预测为真且实际为真的数量占实际为真的数量的比例。

在使用查准率和召回率评估算法时，需要进行权衡两者（是要尽量的不漏掉预测真值还是尽量要预测正确），可以绘制两个值的曲线来提供判断方法。（这个是一对值）。相比之下，$F_1=2{PR\over P+R}$是一个结合查准率和召回率的方法。可以在验证集上尝试不同的临界值（logistics下，用来判断分类结果为0或为1的临界值），然后计算$F_1$的值，取最大值。

### Data For Machine Learning

在哪些情况下，更多的Data会提升算法的效率？会给出条件。

大量数据的合理性：

* 使用一个有很多参数的算法（如线性回归算法中的features或NN中的隐藏单元数），从而降低算法的偏差
* 使用非常大量的数据，用来降低算法的偏差（也避免出现过拟合现象）

经常问问自己：

* 如果一个人类专家看到这些特征值x，能有信心能预测出y值么？证明y可以由x预测得到；
* 能够得到相关的特征值和大量数据来拟合算法么？

如果上面两个都能达到，则会产生很不错的算法。

