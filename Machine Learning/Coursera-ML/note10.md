## What is next？

### Debuging a learing algorithm

如果算法得到的预估值和预期差异比较大，那下一步做法：

1. 获得更多的训练数据集
2. 尝试更小的特征集
3. 获得更多的特征
4. 增加多项式特征
5. 增减正则项中的步进$\lambda$

### Machine learning diagnostic

诊断是一种测试方法，用来测试某种算法是否真的有用。也通常能够洞悉，如何去改进算法的性能。

诊断会花费很多时间来实现它，但是这么做是值得的。

### Evaluating a Hypothesis

后面也会考虑如何解决过拟合和欠拟合问题。

一般按照7：3的比例将数据分为训练数据集和测试数据集（随机选取）。

用训练样本训练参数，然后计算测试集上的误差。

### Model Selection and Train_Validation_Test Sets

如果你想确定对于某组数据最合适的多项式次数是几次，怎样选用正确的特征来构造学习算法或者加入逆需要正确选择算法中的正则化参数$\lambda$，你应该怎么做，这些问题统称为Model Selection。

数据不仅分为训练集和测试集，还可以分为训练集、验证集合测试集。

一般分发：训练数据：交叉验证数据：测试数据=6：2：2

由于使用训练集来选择模型并用来评价并不好，所以增加验证数据来选择数据，然后使用训练数据来评价算法。例如多项式，可以使用交叉数据来验证各个多项式使用训练数据拟合出来的算法，计算出这些模型在交叉数据上的误差，然后使用测试数据来评估算法的泛华误差。（其实就是用交叉验证来评估选择哪个超参数最好）

### Bias vs Var

如何判断方差有问题还是偏差有问题？

当算法在训练集上的偏差和验证集上的偏差都比较大时，则是高偏差，欠拟合的情况；如果算法在训练集上的偏差很小而验证集上的偏差远远大于训练集上的偏差，则说明是高方差。

本章有个图就很清楚，横坐标是变量的次方，纵坐标是偏差大小，验证集上偏差和变量次方是一个口向上的二次方程图形，而训练集上的偏差是一个全局递减的函数，从两个图形的差异就能看出什么时候是高偏差，什么时候是高方差。

### Regularization and Bias_Variance

正则化和偏差、方差有什么关系呢？

$\lambda$的选择会影响实际的效果，如果$\lambda$太大，则$\theta$参数会跟小，以至于为0.可以从$\lambda=0、0.01、0.02、0.04、0.08 … 10$总共12个参数值，使用训练集和这些$\lambda$计算出对应的参数值。然后使用这些参数，在交叉验证集上计算误差值，选择最小值的作为最终的模型。

验证集对不同$\lambda$取值计算得到的模型计算得到验证集误差构成的图形，最低点应该就是最优模型，左边高点是高方差，右边高点是高偏差，整个图形类似二次开口朝上的函数。

### Learning Curves

学习曲线可以用来判断算法是否处于偏差、方差问题。

先要给出$J_{train}(\theta)$和$J_{cv}(\theta)$两个公式，然后横坐标是m（训练集大小），绘制这两个函数随着m的变化，大小的变化，训练误差肯定是一个递增的过程（一个样本时很好拟合），但是最终也将收敛（数据大了训练结果将很好）；而交叉验证误差是一个递减过程，同样也收敛于某个数，原因相似。

__高偏差__：如果一个算法是高偏差的，扩大训练集并不能提高算法效率，而且训练误差和验证集上的误差会出现双高的情况。

__高方差__：训练集误差和验证集误差之间存在一个较大的差值（但是随着训练数据集增大，两者越来越近，当训练数据无限大时，就趋近训练误差。

通过绘制曲线图，然后根据图像对照__高偏差__和__高方差__两个的特点，获得算法具体的问题所在。

### 如何优化自己的算法那

#### Debugging a learning algorithm

如果发现自己的算法（假设集合）在训练数据上的误差太大，难以接受，一般有如下几个步骤可以处理：

* 获得更多的训练数据（对于高方差的情况，有帮助）（先画出曲线图）
* 使用更小的特征集（高方差情况）
* 增加额外的特征（高偏差情况）
* 增加多项式特征（$x_1^2,x_2^2,x_1x_2,etc.$高偏差)
* 减小$\lambda$ （高偏差情况）
* 增加$\lambda$   (高方差情况)

就是看过拟合（高方差）还是欠拟合（高偏差）。

#### Neural networks and overfitting

对于神经网络来说，一般使用一个大型神经网络系统，并使用正则化来修正过拟合问题通常比使用小的神经网络效果更好，就是计算量过大。 