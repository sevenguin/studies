#Hadoop OS
*"大数据胜于好算法"*

**计算机硬盘的发展趋势：寻址时间的提升远远不敌于传输速率的提升**
--所以瓶颈是提升寻址时间或者通过其他方案来提升整体的寻址时间
--Hadoop就像H5，不是一个技术的描述，而是一组相关技术：Common、Avro、MR、HDFS、PIG、Hive、HBase、ZooKeeper、Sqoop、Oozie

Hadoop将MR的输入数据进行分片（input split），Hadoop为每个分片构建一个map任务，	并由该任务来运行用户订立的map函数，从而处理分片中的每条记录（**如何分片？**）
分片越小，越好负载均衡（好的机器执行更多分片）；但是太小，则会产生太多map，消耗过大，所以一般大小是HDFS块大小（默认64M，如果分片大于块大小，那需要的两块数据很大概率上其中一块位于其他机器，那就需要进行网络传输，降低效率，违背了‘使用本地数据计算’的规则），可以调节。

map的数据是写入本地（map产生的是中间数据，输出后即删除），如果map产生的数据传给reduce之前失败，则Hadoop将在另一个节点上重新运行map任务，以再次构建map中间结果
Reduce数据来源是map的输出汇总，按照key汇总给reduce，所以reduce数据一般是需要网络传输，结果存储在HDFS上，一份存在本地机器，其他存在其他机器或机架。

