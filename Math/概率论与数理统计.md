#概率论语数理统计
##事件的概率
###概率是什么
主观概率，可以理解成一种心态或倾向，例如个人对天气下雨可能性判断。这种主要根据，1、个人经验；根据利害关系（如自己没带伞可能就更倾向于预测不下雨）
事件，基本事件可组成新事件，可描述的试验称为一个事件；随机事件、偶然事件；必然事件和不可能事件。
古典概率：如果一个试验有N个可能结果，而事件E恰好包含其中M个结果，则事件E的概率记做：P(E)=M/N
概率的统计定义：一事件出现的可能性大小，应由在多次重复试验中其出现的频繁程度去刻画。这时，频率只是概率的估计而非概率本身。在无数次重复时，假设频率会在实际概率值的很小的邻域内摆动，实验次数越多则邻域越小，如果是无限次，则就等于。——极限问题
假设检验：设根据一定的理论、假设算出某个事件A的概率为p，则这个理论假设是否与实际相符？可以诉诸实验，进行大量重复的试验观察事件A的频率m/n，如果m/n与p相近，则认为实验结果支持了相关理论，反之则有误。

概率的公理化定义
柯尔莫哥洛夫提出概率论公理化（1933年）
公理描述如下：
\\[
设基基本事件组成集合\Omega，一个事件由若干基本事件组成，则\Omega的子集（包括自身和空集）构成一个新的集合F，F中每个成员就称为事件，事件有概率，其大小随事件而异，即概率是事件的函数，与此相应，柯氏公理体系中引入一个定义在F上的函数P，对F中任一成员A，P(A)表示为事件A的概率。对P有一下限制：P(A)值域为[0,1]；P(\Omega)=1, P(\Phi)=0;加法公理(互斥事件值和的概率等于各事件的概率之和）
\\]
公理是为了构成一个完备体系所需要的最少的前提假设或者逻辑基础。
###古典概率计算
排列计较次序而组合不计较
排列：\\[P_r^n = {n *(n-1)*....* (n-r+1)}={n!\over (n-r)!}\\]
组合：\\[C_r^n={P_r^n\over r!}\\]
0!=1
r限制为非负整数，n可以为负数
###事件的运算、条件概率与独立性
一般问题中有许多比较简单的事件，其概率易于计算或是已经有了理论上的假定值，或是根据以往经验已对其值做了充分精确的估计。而我们感兴趣的是一个复杂的事件E，通过种种关系上与简单事件联系起来，以便于用这些简单的事件的概率去算出E的概率。如同对数字做运算，对数字做运算得到新的数字，对事件做运算得出新的事件。
####互斥事件
A/B不能再同一次试验中都发生，则他们是互斥的；对立事件是，非A即B
####事件的和
C=A+B={A发生或B发生}
一定要记住，事件不是已经发生的事情，而是对某种情况的陈述。
####概率加法定理
若干互斥事件之和的概率，等于各事件的概率之和。
\\[P(A_1+A_2+...)=P(A_1)+P(A_2)+...\\]  
AB对立事件，则P(A)=1-P(B)     
####事件的积（交）、事件的差
A、B两个事件，则C={A，B都发生}，记做：\\[A*B，多个的话：\prod_{i=1}^nA_i\\]   
两个事件差：A-B={A发生，B不发生}
由定义就可以知道，分配、交换、结合都适合\\\
A-B=空，则应该是B事件包含A，而不是B=A，在进行事件计算时需要过一下脑子，按照定义来处理，区别于数字的运算    
####条件概率
条件概率就是附加在一定条件下所计算的概率，一般意义上所有概率都是条件概率，因为即便是基础试验，也会有假定条件。但在概率论中不再加入其他条件或假定，则算出的概率叫做无条件概率。在这个情况下条件概率一般范式就是“已知事件发生情况下。。。”    
条件概率记做P(A|B)，表示B发生了，A发生的概率    
P(A|B) = P(AB)/P(B)，P(B)不为0\\\
####事件的独立性，概率乘法定理
如果P(A|B)=P(A)，则说明B发生对A没有影响，则概率论上称为A和B互相独立。    
这时，P(AB)=P(A)P(B)   
用上面式子做推论，如果上面式子满足，则AB独立。    
\\[
对于N个事件，A_1，A_2，...A_i...，A_N，互相独立，则P(A_1A_2...A_i...A_N)=P(A_1)P(A_2)...P(A_i)...P(A_N)\\\
即：P(A_i|P_j...P_n)=P(A_i)
\\]
独立事件任意部分也独立，独立事件组成的事件也独立。    
两两独立的意思是事件任意选两个都是独立的，互相独立的意思是，一群事件都是独立的。    
